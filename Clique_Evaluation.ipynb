{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max clique index  5\n",
      "size of maximum clique  897\n",
      "Average similarity within cluster 0.836888552864182\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-65d0c962d7b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average similarity within cluster\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavgSim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[0motherNodesSim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from pyclustering.cluster import kmeans , clique\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import os\n",
    "\n",
    "from itertools import combinations \n",
    "\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__\n",
    "\n",
    "nCluster=1\n",
    "nNodes=10000\n",
    "maxCliqueSize=397\n",
    "#evaluationflag=0 if we take only the maximum size\n",
    "#evaluationflag=1 if we take top most two clusters based on only size\n",
    "#evaluationflag=2 if we take only the maximum density cluster\n",
    "#evaluationflag=3 Merge until total size greater than clique size\n",
    "#evaluationflag=4 use density and size simultaneously\n",
    "evaluationFlag=4\n",
    "\n",
    "#predictionMode=0 only degree based prediction\n",
    "#predictionMode=1 only centroid similarity based prediction\n",
    "#predictionMode=2 both criteria\n",
    "#predictionMode=3 print all criteria based results simultaneously\n",
    "predictionMode=3\n",
    "#function to find similarity between two vecs\n",
    "\n",
    "def getVecNorm(vec1):\n",
    "    norm=0\n",
    "    for i in range(len(vec1)):\n",
    "        norm = norm+vec1[i]*vec1[i]\n",
    "    norm = np.sqrt(norm)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def findSimilarity(vec1,vec2):\n",
    "    sim=0\n",
    "    for i in range(len(vec1)):\n",
    "        sim = sim+vec1[i]*vec2[i]\n",
    "    vec1_norm=getVecNorm(vec1)\n",
    "    vec2_norm= getVecNorm(vec2)\n",
    "    sim = sim/(vec1_norm*vec2_norm)\n",
    "    sim = (sim+1)/2\n",
    "    return sim\n",
    "\n",
    "degreeDic={}\n",
    "for i in range(1,nNodes+1):\n",
    "    degreeDic[str(i)]=0\n",
    "\n",
    "\n",
    "with open(\"C:/Users/Procheta/Downloads/edge_file_10000_10_0.5.txt\", \"r\") as gtcl:\n",
    "    for line in gtcl:\n",
    "        x=line.strip().split(\" \")\n",
    "        x1=x[0]\n",
    "        try:\n",
    "            degreeDic[x1]=degreeDic[x1]+1\n",
    "            x1=x[1]\n",
    "            degreeDic[x1]=degreeDic[x1]+1\n",
    "        except:\n",
    "            v=0\n",
    "        \n",
    "    \n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3\n",
    "\n",
    "def findClusterOverlap(clusters,clique):\n",
    "    maxCount=0\n",
    "    index=0\n",
    "    for j in range(len(clusters)):\n",
    "        c=clusters[j]\n",
    "        clusterSize=len(c)\n",
    "        count=0\n",
    "        l=intersection(c,clique)\n",
    "        print(\"For cluster number \",j, \"fraction of total Cluster size\", (len(c)), \" fraction of clique \", (len(l)/len(clique)))\n",
    "        if maxCount < len(l):\n",
    "            maxCount=len(l)\n",
    "            index=j\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "##Returning top 2 clusters            \n",
    "def findMaxCluster(clusters, maxCliqueSize,WordVecDic):\n",
    "    maxCluster=[]\n",
    "    if evaluationFlag==0 or evaluationFlag==1:\n",
    "        maxSize=0\n",
    "        for i in range(len(clusters)):\n",
    "            cluster=clusters[i]\n",
    "            if maxSize < len(cluster):\n",
    "                maxSize=len(cluster)\n",
    "                maxCluster=cluster\n",
    "        print(\"Size of maximum cluster \", maxSize)\n",
    "        print(\"Fraction of joint cluster size with respect to total number of nodes\", (maxSize)/nNodes)\n",
    "        secCluster=[]\n",
    "        secMax=0\n",
    "    if evaluationFlag==1:\n",
    "            for i in range(len(clusters)):\n",
    "                cluster=clusters[i]\n",
    "                if maxSize != len(cluster):\n",
    "                    if secMax < len(cluster):\n",
    "                        secMax=len(cluster)\n",
    "                        secCluster=cluster\n",
    "            print(\"Size of second maximum cluster \", secMax)\n",
    "            print(\"Fraction of joint cluster size with respect to total number of nodes\", (maxSize+secMax)/nNodes)\n",
    "            for i in range(len(secCluster)):\n",
    "                maxCluster.append(secCluster[i])\n",
    "    if evaluationFlag==2:\n",
    "        maxSim=0\n",
    "        clusterIndex=0\n",
    "        for i in range(len(clusters)):\n",
    "            cluster=clusters[i]\n",
    "            sim=findAvgSimilarityWithinCluster(cluster, WordVecDic)\n",
    "            if maxSim < sim:\n",
    "                maxSim = sim\n",
    "                clusterIndex=i\n",
    "        maxCluster=clusters[clusterIndex]\n",
    "        print(\"max Cluster index \", clusterIndex)\n",
    "    if evaluationFlag==3:\n",
    "        maxSize=0\n",
    "        clusterIndex=0\n",
    "        centroids=[]\n",
    "        simDict={}\n",
    "        for i in range(len(clusters)):\n",
    "            cluster=clusters[i]\n",
    "            centroids.append(findCentroid(cluster, WordVecDic))\n",
    "            if maxSize < len(cluster):\n",
    "                maxSize = len(cluster)\n",
    "                clusterIndex=i\n",
    "        print(\"max Cluster index \", clusterIndex)\n",
    "        maxCluster=clusters[clusterIndex]\n",
    "        maxClusterCentroid=centroids[clusterIndex]\n",
    "        similarities=[]\n",
    "        for i in range(len(clusters)):\n",
    "            centroidVec=centroids[i]\n",
    "            if i != clusterIndex:\n",
    "                sim=findSimilarity(maxClusterCentroid,centroidVec)\n",
    "                simDict[sim]=i\n",
    "                similarities.append(sim)\n",
    "        similarities.sort()\n",
    "        for i in range(len(similarities)):\n",
    "            sim=similarities[i]\n",
    "            index=simDict[sim]\n",
    "            cluster=clusters[index]\n",
    "            if len(maxCluster) < maxCliqueSize:\n",
    "                print(\"cluster index \", index)\n",
    "                for j in range(len(cluster)):\n",
    "                    maxCluster.append(cluster[j])\n",
    "            else:\n",
    "                break;\n",
    "                \n",
    "        if evaluationflag ==4 :\n",
    "            denseVal=0\n",
    "            clusterIndex=0\n",
    "            for i in range(len(clusters)):\n",
    "                x=findAvgSimilarityWithinCluster(clusters[i], WordVecDic)\n",
    "                y=len(clusters[i])\n",
    "                z= x*y\n",
    "                if denseVal < z:\n",
    "                    denseVal=z\n",
    "                    clusterIndex=i\n",
    "            maxCluster=clusters[i]\n",
    "            \n",
    "    return maxCluster\n",
    "\n",
    "\n",
    "def findAvgSimilarityWithinCluster(cluster, WordVecDic):\n",
    "    similarity=0\n",
    "    for i in range(len(cluster)):\n",
    "        vec1=WordVecDic[str(cluster[i])]\n",
    "        for j in range(i+1, len(cluster)):\n",
    "            vec2=WordVecDic[str(cluster[j])]\n",
    "            similarity=similarity+findSimilarity(vec1,vec2)\n",
    "    if len(cluster) > 1:\n",
    "        similarity=similarity/(len(cluster)*(len(cluster)-1)/2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def findCentroid(cluster, vecDic):\n",
    "    centroid=[]\n",
    "    for i in range(len(vecDic[str(cluster[0])])):\n",
    "        centroid.append(0)\n",
    "    \n",
    "    for i in range(len(cluster)):\n",
    "        x=cluster[i]\n",
    "        vec1=vecDic[str(x)]\n",
    "        for j in range(len(vec1)):\n",
    "            centroid[j] = centroid[j]+vec1[j]\n",
    "    clusterSize=len(cluster)\n",
    "    for i in range(len(centroid)):\n",
    "        centroid[i] = centroid[i]/clusterSize\n",
    "    return centroid\n",
    "\n",
    "def centroidbasedPrdiction(cluster,vecDic, maxClique):\n",
    "    centroid=findCentroid(cluster, vecDic)\n",
    "    simValue=[]\n",
    "    simDic={}\n",
    "    for i in range(len(cluster)):\n",
    "        x=cluster[i]\n",
    "        pointVec=vecDic[str(x)]\n",
    "        sim=findSimilarity(pointVec, centroid)\n",
    "        simValue.append(sim)\n",
    "        simDic[sim]=x\n",
    "         \n",
    "        \n",
    "    simValue.sort()\n",
    "    count=0\n",
    "    clique=[]\n",
    "    for i in range(len(simValue)):\n",
    "        clique.append(simDic[simValue[i]])\n",
    "        if count == maxClique:\n",
    "            break\n",
    "        count=count +1\n",
    "    return clique\n",
    "    \n",
    "\n",
    "def predictClique(cluster, degreeArray, vecDic, maxClique):\n",
    "    clique=[]\n",
    "    clique1=[]\n",
    "    if predictionMode==0 or predictionMode==2 or predictionMode==3:\n",
    "        for i in range(len(cluster)):\n",
    "            if degreeArray[str(cluster[i])] >= (20-1) :\n",
    "                clique.append(cluster[i])\n",
    "        clique1=clique\n",
    "        if len(clique) != 0:\n",
    "            print(\"Degree based Appoach\")\n",
    "            evaluateprediction(clique, maxClique)\n",
    "        else:\n",
    "            print(\"Degree based prediction could't predict any clique\")\n",
    "    if predictionMode==2:\n",
    "        cluster=clique\n",
    "    if predictionMode==1 or predictionMode==2 or predictionMode==3:\n",
    "        clique=centroidbasedPrdiction(cluster,vecDic, maxClique)\n",
    "        if len(clique) != 0:\n",
    "            print(\"Centroid based Appoach\")\n",
    "            evaluateprediction(clique, maxClique)\n",
    "        else:\n",
    "            print(\"Centroid based prediction could't predict any clique\")\n",
    "    if predictionMode==3:\n",
    "        clique=[]\n",
    "        if len(clique1) !=0:\n",
    "            clique=centroidbasedPrdiction(clique1,vecDic, maxClique)\n",
    "        if len(clique) != 0:\n",
    "            print(\"Combined Appoach\")\n",
    "            evaluateprediction(clique, maxClique)\n",
    "        else:\n",
    "            print(\"Combined approach based prediction could't predict any clique\")\n",
    "    \n",
    "    return clique\n",
    "def evaluateprediction(cluster, clique):\n",
    "    count=0\n",
    "    for i in range(len(clique)):\n",
    "        if clique[i] in cluster:\n",
    "            count = count+1\n",
    "    #print(count, len(cluster))\n",
    "    print(\"Precision \", count/len(cluster))\n",
    "    print(\"Recall \", count/len(clique))\n",
    "\n",
    "WordVecDic={}\n",
    "vecs=[]\n",
    "ids=[]\n",
    "flag=0\n",
    "with open(\"C:/Users/Procheta/Downloads/output_0.5.vec\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if flag == 0:\n",
    "            flag=1\n",
    "        else:\n",
    "            vec=[]\n",
    "            x=line.split(\"\\n\")[0]\n",
    "            words=x.split(\" \")\n",
    "            key=words[0]\n",
    "            count=0\n",
    "            for word in words:\n",
    "                if count>=1:\n",
    "                    try:\n",
    "                        vec.append(float(word))\n",
    "                    except:\n",
    "                        v=0\n",
    "                else:\n",
    "                    count=1\n",
    "            try:\n",
    "                ids.append(int(key))\n",
    "                WordVecDic[key]=vec\n",
    "                vecs.append(vec)\n",
    "            except:\n",
    "                print(\"key \", key)\n",
    "                #print(line)\n",
    "                        \n",
    "clique_list=[]\n",
    "maxCliqueSize=0\n",
    "maxCliqueIndex=0\n",
    "index=0\n",
    "\n",
    "with open(\"C:/Users/Procheta/Downloads/ground_truth_clique_list_10000_10_0.5.txt\", \"r\") as gtcl:\n",
    "    for line in gtcl:\n",
    "        x=line.strip().split(\" \")\n",
    "        clique=[]\n",
    "        for x1 in x:\n",
    "            clique.append(int(x1))\n",
    "        clique_list.append(clique)\n",
    "        if maxCliqueSize < len(clique):\n",
    "            maxCliqueSize=len(clique)\n",
    "            maxCliqueIndex=index\n",
    "        index=index+1\n",
    "\n",
    "        \n",
    "print(\"max clique index \",maxCliqueIndex) \n",
    "print(\"size of maximum clique \",maxCliqueSize)\n",
    "maxClique=clique_list[maxCliqueIndex]\n",
    "\n",
    "\n",
    "###computing similarity within cluster######\n",
    "avgSim=0\n",
    "#print(WordVecDic.keys())\n",
    "for i in range(len(maxClique)):\n",
    "    vec1=WordVecDic[str(maxClique[i])]\n",
    "    for j in range(i+1,len(maxClique)):\n",
    "        vec2= WordVecDic[str(maxClique[j])]\n",
    "        sim=findSimilarity(vec1,vec2)\n",
    "        avgSim=avgSim+sim\n",
    "\n",
    "avgSim=avgSim/(len(maxClique)*(len(maxClique)-1)/2)\n",
    "\n",
    "print(\"Average similarity within cluster\", avgSim)\n",
    "\n",
    "otherNodesSim=0\n",
    "\n",
    "for i in range(len(maxClique)):\n",
    "    vec1=WordVecDic[str(maxClique[i])]\n",
    "    for j in range(len(ids)):\n",
    "        if ids[j] not in maxClique:\n",
    "            vec2= WordVecDic[str(ids[j])]\n",
    "            sim=findSimilarity(vec1,vec2)\n",
    "            otherNodesSim=otherNodesSim+sim\n",
    "        \n",
    "\n",
    "otherNodesSim = otherNodesSim/((len(ids)-len(maxClique))*len(maxClique))\n",
    "print(\"Average similarity of clique with other nodes\", otherNodesSim)\n",
    "\n",
    "print(\"ratio of within clique similarity vs other node similarity \", avgSim/otherNodesSim)\n",
    "\n",
    "\n",
    "\n",
    "clustering = AffinityPropagation().fit(vecs)\n",
    "cluster_centers_indices = clustering.cluster_centers_indices_\n",
    "nCluster=len(cluster_centers_indices)\n",
    "\n",
    "\n",
    "print(\"Number of clusters created\", nCluster)\n",
    "\n",
    "clusters=[]\n",
    "\n",
    "for i in range(nCluster):\n",
    "    x=[]\n",
    "    clusters.append(x)\n",
    "    \n",
    "for i in range(len(clustering.labels_)):\n",
    "    clusters[clustering.labels_[i]].append(int(ids[i]))\n",
    "\n",
    "print(\"Custering completed\")    \n",
    "\n",
    "\n",
    "clique=clique_list[maxCliqueIndex]\n",
    "findClusterOverlap(clusters,clique)\n",
    "\n",
    "x=findMaxCluster(clusters,maxCliqueSize,WordVecDic)\n",
    "print(\"MaxClique Predictions\")\n",
    "print(\"Max Size based prediction\")\n",
    "evaluateprediction(x, clique)\n",
    "cl=predictClique(x, degreeDic, WordVecDic, clique)\n",
    "#print(\"Predicted \", cl)\n",
    "#print(x)\n",
    "#evaluateprediction(cl, clique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
